# L3: Curse of Dimensionality: Convex Hulls

Given a set of points $X \subset \mathbb{R}^d$, the *convex hull $CH(X)$* is 

 - the smallest convex set which contains $X$
 - if you put nails in a board, and surround with rubber band -- it is inside the rubber band
 - line segment between any pair of points is in $CH(X)$.  Recursively, line segments between points on these line segments in $CH(X)$.  In $d$ dimensions, recurse up to $d$ times...
 - point $p \in CH(X)$ if there exists $\alpha \in [0,1]^d$ so $\alpha_j > 0$ and $\sum_j \alpha_j = 1$; then $p = \sum_j \alpha_j x_j$ (where $X = \{x_j\}_j$)
 - point $p \notin CH(X)$ if and only if there exists a hyperplane $H$ which can separate $p$ from all points in $X$.  
 - the intersection of all balls (and hence all halfspaces) which contain $X$.  
 
The convex hull $CH(X)$ is the most spatially compact way to represent $X$ \
... and intimately tied to *linear classification*.  


##  Convex Hull for $d=2,3$

For $d=2$, store sequence of edges connecting pairs of vertices as one "walks" around boundary.  \
Takes $O(n \log n)$ time, $O(n)$ space.  

For $d=3$, it is more complicated.  Need to store edges, and also *faces*: 

 - $2$-dimensional objects with edges on boundary.  
 - in general position, these are filled triangles. 
 
*How hard, big is it to construct?*

 - Storing all points, edges, faces is $O(n)$ space.  \
   Planar graph (wrapped on sphere)
 - Can build in $O(n \log n)$ time


##  Convex Hull for High Dimensions

*How do we store/represet $CH(X)$ in high-dimensions?*

 - just points?
 - just faces?
 - all $j$-dimensional (for $j \in [0, 1, \ldots, d-1]$) facets?


*Moment curve:*  $x(t) = (t^1, t^2, \ldots, t^d) \in \mathbb{R}^d$ for $t \in \mathbb{R}$.  \
For $n$ (lets say $n > 2d$) points $X$ on moment curve, they form a *cyclic polytope*, for which all subsets of size $j+1$ for $j < \lfloor d/2 \rfloor$ define a $j$-dimensional face on the convex hull.  \
For $j = \lfloor d/2 \rfloor-1$, there are ${n \choose j+1} = \Theta(n^{\lfloor d/2 \rfloor})$ such $j$-dimensional facets.  \
Can be shown the number of $j$-dimensional facets for $j > \lfloor d/2 \rfloor$ is also  $\Theta(n^{\lfloor d/2 \rfloor})$.  \
Including $\Theta(n^{\lfloor d/2 \rfloor})$ of the faces (the $(d-1)$-dimensional facets).  \
*Upper Bound Theorem:*  This is the most possible.  


## Approximate Convex Hulls

*Can we break exponential dependence on $d$ is we approximate?*

Most common definition: *$\varepsilon$-kernel coreset*.  \
A subset $S \subset X$ approximates all directions within $(1+\varepsilon)$.  

Unit direction $u \in \mathbb{R}^d$ such that $\|u\|=1$.  or say $u \in \mathbb{S}^{d-1}$\
Width in direction $u$ is $wid_u(X) = \max_{x \in X} \langle x, u \rangle - \min_{x \in X} \langle x, u \rangle$.  \
Goal for $S$ is for **all** directions $u$ that 
$$
wid_u(X) - wid_u(S) \leq \varepsilon \cdot wid_u(X)
$$

Hardest case is ball $B$.  \
In $d=2$ it requires $\Omega(1/\sqrt{\varepsilon})$ points\
$\varepsilon = 0.01=1/100$ (so $1\%$ error) needs only about $10$ points.  

In high dimensions it requires $\Omega(1/\varepsilon^{\lfloor d/2 \rfloor})$ points.  \
Exist algorithm to compute $\varepsilon$-kernel of size $O(1/\varepsilon^{\lfloor d/2 \rfloor})$ points.  

$(1+\varepsilon)$-width approximation by faces also requires $\Omega(1/\varepsilon^{\lfloor d/2 \rfloor})$ faces.  



## John Ellipsoid Approximation

An *ellipsoid* is a ball in $\mathbb{R}^d$ after any affine transformation.  \
Let $A \in \mathbb{R}^{d \times d}$ full-rank matrix.  \
An affine transformation of $x \in \mathbb{R}^d$ by $A$ is simply $x' = Ax + t$ for $t \in \mathbb{R}^d$.  \
Thus an ellipse $E_{A,t}$ is the set of points $x' \in \mathbb{R}^d$ such that $\{x' = Ax+t \mid x \in B\}$ where $B$ is a unit ball.  

An ellipsoid is not any "round" shape.  \
It is controlled by an orthonormal basis $U = [u_1, u_2, \ldots, u_d]$ where each $\|u_j\|=1$ and each pair $u_j, u_{j'}$ are orthogonal so $\langle u_j, u_{j'} \rangle = 0$.  \
Then each $j$ is associated with a scaling $\lambda_j$.  
*(indeed, these are the eigenvectors $u_j$ and values $\lambda_j$ of $A$)*\
For an ellipsoid $E$ with those basis and scaling, and center $t$, then a point $x \in \mathbb{R}^d$ is in $E$ if
$$
  \sum_{j=1}^d  \langle u_j, x-t \rangle^2 / \lambda_j^2 \leq 1.
$$

*How well can we approximate a convex set $K$ (e.g., $K = CH(X)$) with an ellipsoid?*

Lowner-John's Ellipsoid theorem says for any convex set $K \subset \mathbb{R}^d$ there exists an ellipsoid $E$ so 
$$
  (1/d)E \subset K \subset E
$$
This $E$ is the minimum volume ellipsoid which circumscribes $K$.  This is the best possible dilation ratio.  


### Making $CH(X)$ Fat

Compute Lowner-John Ellipsoid $E_{A,t}$ for $CH(X)$.  \
Invert data $X$ by $A^{-1}$; that is
$$
X' = \{x' = A^{-1} x \mid x \in X\}
$$
Now $X'$ is *$d$-fat*, this means that 
$$
\frac{ \max_{u \in \mathbb{S}^{d-1}} wid_u(X')}{ \min_{u \in \mathbb{S}^{d-1}} wid_u(X')} \leq d
$$

